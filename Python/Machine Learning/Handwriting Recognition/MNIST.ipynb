{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<pre>\n",
    "   __  ______  ____  ___    _   _______ ____  ________________________  __\n",
    "  / / / / __ \\/ __ )/   |  / | / / ___// __ \\/ ____/  _/ ____/_  __/\\ \\/ /\n",
    " / / / / /_/ / __  / /| | /  |/ /\\__ \\/ / / / /    / // __/   / /    \\  / \n",
    "/ /_/ / _, _/ /_/ / ___ |/ /|  /___/ / /_/ / /____/ // /___  / /     / /  \n",
    "\\____/_/ |_/_____/_/  |_/_/ |_//____/\\____/\\____/___/_____/ /_/     /_/   \n",
    "                                                                          \n",
    "</pre>\n",
    "<p>\n",
    "<b>Department:</b> Urbansociety Research\n",
    "\n",
    "<b>Clearance:</b> Unrestricted - 0\n",
    "\n",
    "<b>Description:</b> Image classification model that can read handwritten digits using Googles TensorFlow modules and the DeepAI MNIST dataset. See https://en.wikipedia.org/wiki/Artificial_neural_network for more information on neural networks.\n",
    "\n",
    "<b>License:</b> MIT License\n",
    "\n",
    "    Copyright (c) 2021 Urbansociety\n",
    "\n",
    "    Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "    of this software and associated documentation files (the \"Software\"), to deal\n",
    "    in the Software without restriction, including without limitation the rights\n",
    "    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "    copies of the Software, and to permit persons to whom the Software is\n",
    "    furnished to do so, subject to the following conditions:\n",
    "\n",
    "    The above copyright notice and this permission notice shall be included in all\n",
    "    copies or substantial portions of the Software.\n",
    "\n",
    "    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "    SOFTWARE.\n",
    "\n",
    "<b>Dependencies:</b>\n",
    "    \n",
    "    Python 3.9.7    -   For more information visit https://www.python.org<br>\n",
    "    TensorFlow      -   For more information visit https://www.tensorflow.org<br>\n",
    "    Keras           -   For more information visit https://keras.io<br>\n",
    "    Matplotlib      -   For more information visit https://matplotlib.org<br>\n",
    "\n",
    "<b>Datasets:</b>\n",
    "    \n",
    "    MNIST Dataset   -   For more information visit https://deepai.org/dataset/mnist\n",
    "\n",
    "<b>Tested platforms:</b>\n",
    "\n",
    "\tLinux:\n",
    "\n",
    "\t\tFedora 34\t-\tFor more information visit https://getfedora.org/\n",
    "\n",
    "\n",
    "</p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Import modules</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Download the dataset</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Download the OpenAI MNIST dataset\n",
    "mnist=tf.keras.datasets.mnist\n",
    "\n",
    "# Prepare the data and split it into a train and a test dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Look at the first image</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Look at the first image\n",
    "x_train[0].shape\n",
    "first_image=x_train[0]\n",
    "\n",
    "# Show the image in grayscale\n",
    "plt.imshow(first_image, cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb9fcb47c0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Create the neural network</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create the neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28,28]), # For the neural net we need a list of values not a matrix\n",
    "    tf.keras.layers.Dense(128, activation='relu'), # A dense layer is the same as a fully connected layer or the linear layer in pytorch\n",
    "    tf.keras.layers.Dropout(0.2), # Dropout means some of the outputs of the dense layer will be set to zero so that the network doesn't learn all the images by heart\n",
    "    tf.keras.layers.Dense(10) # Output layer. There are 10 outputs for 10 classes\n",
    "])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-06 21:43:56.284655: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-06 21:43:56.308629: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-06 21:43:56.309726: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Make a prediction on the untrained model</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Make a prediction for the first image\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "\n",
    "# Show prediction as probability\n",
    "tf.nn.softmax(predictions).numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.07924489, 0.09139222, 0.0696773 , 0.16694754, 0.10660441,\n",
       "        0.09405775, 0.15975605, 0.04279941, 0.07556552, 0.11395483]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Create a loss function</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create a loss function\n",
    "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "model.compile(optimizer='adam',\n",
    "                loss=loss_fn,\n",
    "                metrics=['accuracy']\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Train the model</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Train the model to reduce loss for a fixed number of epochs\n",
    "model.fit(x_train, y_train, epochs=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-06 21:44:14.789051: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-06 21:44:14.804028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1800055000 Hz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 35s 17ms/step - loss: 0.4763 - accuracy: 0.8625\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1527 - accuracy: 0.9565\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1105 - accuracy: 0.9665\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0920 - accuracy: 0.9711\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0781 - accuracy: 0.9763\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0664 - accuracy: 0.9792\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0555 - accuracy: 0.9824\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0527 - accuracy: 0.9823\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0487 - accuracy: 0.9837\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0438 - accuracy: 0.9854\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0444 - accuracy: 0.9852\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0381 - accuracy: 0.9871\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0347 - accuracy: 0.9888\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0331 - accuracy: 0.9891\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0310 - accuracy: 0.9893\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0321 - accuracy: 0.9890\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0285 - accuracy: 0.9898\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0250 - accuracy: 0.9913\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0238 - accuracy: 0.9917\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0246 - accuracy: 0.9916\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0224 - accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0217 - accuracy: 0.9921\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0198 - accuracy: 0.9926\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0217 - accuracy: 0.9929\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0182 - accuracy: 0.9934\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0185 - accuracy: 0.9935\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0169 - accuracy: 0.9937\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0166 - accuracy: 0.9939\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0158 - accuracy: 0.9945\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0178 - accuracy: 0.9942\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0165 - accuracy: 0.9940\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0168 - accuracy: 0.9941\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0161 - accuracy: 0.9947\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0152 - accuracy: 0.9950\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0146 - accuracy: 0.9949\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb80a36ac0>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Evaluate the trained Model</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Show information about the test set\n",
    "x_test.shape\n",
    "\n",
    "# Evaluate the model to see how accurate it predicts the integers in the test set\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 - 2s - loss: 0.1258 - accuracy: 0.9803\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.1258234679698944, 0.9803000092506409]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Test the trained Model</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Show the first test image in grayscale\n",
    "test_image=x_test[0]\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "# Make prediction for the image\n",
    "predictions = model(x_test[:1]).numpy()\n",
    "highest_index=0\n",
    "for x in tf.nn.softmax(predictions):\n",
    "    for i,y in enumerate(x):\n",
    "        if(y>x[highest_index]):\n",
    "            highest_index=i\n",
    "print(f\"[Prediction]: The image is a {highest_index}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Prediction]: The image is a 7\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "713a977bc027d66ae3945b8c91b9769c41ec904a69219893298b3eaa62ecf018"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('USR_AI': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}